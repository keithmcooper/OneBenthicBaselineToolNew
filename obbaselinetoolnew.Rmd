---
title: "OneBenthic Baseline Tool"
author: ''
output:
  flexdashboard::flex_dashboard:
    theme: cerulean
    css: style.css
runtime: shiny
resource_files:
- config.yml
- www/OBBTWelcomeImage.png
---

```{r setup, include = FALSE}
library(flexdashboard)
library(shiny)
library(jsonlite)
library(maptools)
library(ggplot2)
library(tidyr)
library(dplyr)
library(purrr)
library(leaflet)
library(DT)
library(mapview)
library(leaflet)
library(leafem)
library(leaflet.extras)
library(htmltools)
library(mapview)
library(plotly)
library(pool)
library(sf)
library (RPostgres)
library(DBI)
library(geojsonio)
library(RPostgreSQL)
library(raster)
library(pals)
library(RColorBrewer)
library(knitr)
library(rmarkdown)
require(ggplot2)
require(data.table)
require(raster)
require(ggcorrplot)
require(ggdendro)
require(ggpubr)
require(ggpmisc)
require(grid)
require(gridExtra)
require(tibble)
require(kableExtra)
library(patchwork)
library(ggpubr)
library(shinybusy)
#options(show.error.messages = FALSE)
#__________________________________________________________________________________________
#### CREATE A CONNECTION TO OneBenthic LIVE ####
Sys.setenv(R_CONFIG_ACTIVE = "one_benthic")

dw <- config::get()

pool <- dbPool(drv = dbDriver(dw$driver),
               dbname = dw$database,
               host = dw$server,
               port =  dw$port,
               user = dw$uid,
               password = dw$pwd)
#__________________________________________________________________________________________
#### GET STATION DATA ####
data <- dbGetQuery(pool,                   
                  "select 
s.samplecode,
s.year,
s.gear_gearcode,
s.samplelong,
s.samplelat,
cl.baselinefaunalcluster_faunalcluster as cluster,
cl.baselinephycluster_phycluster as phycluster,
st.stationcode,
sus.survey_surveyname,
stationgroup,
stationsubgroup1


from derived_data.cluster as cl
inner join samples.sample as s on s.samplecode = cl.sample_samplecode
inner join associations.samplestation as ss on ss.sample_samplecode = s.samplecode
inner join associations.station as st on st.stationcode = ss.station_stationcode
inner join associations.surveysample as sus on sus.sample_samplecode = s.samplecode
where baselinefaunalcluster_faunalcluster != 'none' 
")
#AND baselinephycluster_phycluster != 'none'
#View(data)
#unique(data$phycluster)
#str(data)

data$phycluster <- as.numeric(data$phycluster)
#__________________________________________________________________________________________
#### GET SAMPLE DATA ####
samclus <- dbGetQuery(pool,                   
                  "select 
s.samplecode,
s.year,
s.gear_gearcode,
s.samplelong,
s.samplelat,
cl.baselinefaunalcluster_faunalcluster as cluster,
cl.baselinephycluster_phycluster as phycluster,
sus.survey_surveyname as survey



from derived_data.cluster as cl
inner join samples.sample as s on s.samplecode = cl.sample_samplecode
inner join associations.surveysample as sus on sus.sample_samplecode = s.samplecode
where baselinefaunalcluster_faunalcluster != 'none'
and sus.survey_surveyname !='REBENT: Benthic Networking'
and sus.survey_surveyname !='Macrobenthos from the Norwegian waters'
and sus.survey_surveyname !='Macrozoobenthos data from the southeastern North Sea in 2000'
and sus.survey_surveyname !='Dutch long term monitoring of macrobenthos in the Dutch Continental Economical Zone of the North Sea'
and sus.survey_surveyname !='Macrobenthos monitoring at long-term monitoring locations, period 2001-ongoing'
and sus.survey_surveyname !='North Sea Benthos Survey'")
#__________________________________________________________________________________________
#### BRING IN ACTIVITY LAYERS ####

## Bring in api links table
apilink <- st_read (dsn = pool, query = "SELECT * FROM spatial.apilinks")

## Select only the apilink
euowfapilink <- apilink[apilink$id ==1 , "apilink"]
owfapilink <-apilink[apilink$id ==2 , "apilink"]
owf_cabapilink <-apilink[apilink$id ==3 , "apilink"]
waveapilink <-apilink[apilink$id ==4 , "apilink"]
tidalapilink <-apilink[apilink$id ==5 , "apilink"]
tidal_cabapilink <-apilink[apilink$id ==6 , "apilink"]
R4_charaapilink <-apilink[apilink$id ==7 , "apilink"]
R4_bidapilink <-apilink[apilink$id ==8 , "apilink"]

## API
euowf <- readLines(as.character(euowfapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
owf <- readLines(as.character(owfapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
owf_cab <- readLines(as.character(owf_cabapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
wave <- readLines(as.character(waveapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
tidal <- readLines(as.character(tidalapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
tidal_cab <- readLines(as.character(tidal_cabapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
R4_chara <- readLines(as.character(R4_charaapilink)) %>% paste(collapse = "\n") %>% geojson_sf()
R4_bid <- readLines(as.character(R4_bidapilink)) %>% paste(collapse = "\n") %>% geojson_sf()

## SPATIAL DATA FROM ONEBENTHIC
oga <- st_read(pool, query = "SELECT * FROM spatial.oga_licences_wgs84;")
mcz <-  st_read(pool, query = "SELECT * FROM spatial.c20190905_offshorempas_wgs84 WHERE site_statu = 'MCZ - Secretary of State';")
sac <-  st_read(pool, query = "SELECT * FROM spatial.c20190905_offshorempas_wgs84 WHERE site_statu = 'SAC'or site_statu = 'cSAC';")
ncmpa <-  st_read(pool, query = "SELECT * FROM spatial.c20190905_offshorempas_wgs84 WHERE site_statu = 'NCMPA';")
disp  <-  st_read(pool, query = "SELECT * FROM spatial.disposalSiteJan2020;")
ref <- st_read(pool, query = "SELECT * FROM spatial.ref_box_all;")
siz<- st_read(pool, query = "SELECT * FROM ap_marine_aggregate.extraction_areas_siz where droped = FALSE;")
agg <- st_read(pool, query = "SELECT * FROM ap_marine_aggregate.extraction_areas where droped = FALSE;")

## Check CRS
st_crs(mcz)#Coordinate Reference System: NA
st_crs(sac)#Coordinate Reference System: NA
st_crs(ncmpa)#Coordinate Reference System: NA
st_crs(oga)#Coordinate Reference System: NA
st_crs(disp)#Coordinate Reference System: NA
st_crs(agg) # 4326
st_crs(siz) # 4326
st_crs(owf)#Coordinate Reference System: NA
st_crs(owf_cab)#Coordinate Reference System: NA
st_crs(wave)#Coordinate Reference System: NA
st_crs(tidal)#Coordinate Reference System: NA
st_crs(tidal_cab)#Coordinate Reference System: NA
st_crs(R4_chara)#Coordinate Reference System: NA
st_crs(R4_bid)#Coordinate Reference System: NA

## Set CRS where necessary
st_crs(mcz) <- 4326
st_crs(sac) <- 4326
st_crs(ncmpa) <- 4326
st_crs(oga) <- 4326
st_crs(disp) <- 4326

```

```{r}
## Add busy spinner from shinybusy package
#https://dreamrs.github.io/shinybusy/
#https://cran.r-project.org/web/packages/shinybusy/shinybusy.pdf
add_busy_spinner(spin = "fading-circle",position = "bottom-left",margins = c(40, 60),color = "#044D94",timeout = 300,height = "70px",width = "70px")##FFFFFF #0D4581
```

Column {.sidebar data-width=300}
-----------------------------------------------------------------------
```{r}
br()
#### ADD SELECTION BOXES
#selectInput(inputId="progInput", multiple = F,h4("Select Monitoring Programme",style="color:#808080"),choices =unique(data$stationgroup))
#selectInput(inputId="regionInput", multiple = F,h4("Select Survey Array",style="color:#808080"),choices =NULL)

 #__________________________________________________________________________________________           
#### PROVIDE INPUT OPTIONS FOR ARRAYS AVAILABLE UNDER INITIAL INPUT #### 
  #https://stackoverflow.com/questions/48376156/updating-a-selectinput-based-on-previous-selectinput-under-common-server-functio
#  observeEvent(input$progInput,{
#    updateSelectInput(session,'regionInput',
#                      choices=unique(data$stationsubgroup1[data$stationgroup==input$progInput]))
#  })
    
# observeEvent(input$regionInput,{
#     updateSelectInput(session,'siteInput',
#                       choices=levels(factor(unique(agg$area_numbe[agg$region==input$regionInput]))))
#   }) 

# selectInput(inputId="siteInput", multiple = F,h4("Select Site",style="color:#808080"),choices =NULL)
## DROP DOWN LIST OF EXT AREA TO ADD TO MAP 
#selectInput(inputId="extractionareaInput", multiple =F,h4("Select Extraction Area",style="color:#808080"),choices =levels(factor(unique(agg$area_numbe))))
##############################################
 #####################################
selectInput(inputId="progInput", multiple = F,h4("Select Monitoring Programme",style="color:#808080"),choices =unique(data$stationgroup))
selectInput(inputId="regionInput", multiple = F,h4("Select Survey Array",style="color:#808080"),choices =NULL)

  observeEvent(input$progInput,{
    updateSelectInput(session,'regionInput',
                      choices=unique(data$stationsubgroup1[data$stationgroup==input$progInput]))
  })

  
 

observeEvent(input$regionInput,{
  
   # test() = levels( factor(unique(agg$area_numbe[agg$region==input$regionInput]))  )[1]
    updateSelectInput(session,'siteInput',
                     choices=levels(factor(unique(agg$area_numbe[agg$region==input$regionInput]))))
 })

 selectInput(inputId="siteInput", multiple = F,h4("Select Site",style="color:#808080"), choices = NULL  ) 
```


Column {data-width=500}
-----------------------------------------------------------------------

### Map

```{r}
library(terra)
library(raster)
library(sf)
## AGGREGATE REGIONS
addPolylines <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_regions;")# Read in data


## Bring in assemblage tif
#assemblages <- rast('www/AssemblageMaxClass_Apr22.tif')
#assemblages.agg <- aggregate(assemblages, fact=2,fun = modal)
#writeRaster(assemblages.agg,'www/AssemblageMaxClass_Apr22_agg.tif',overwrite=TRUE)#format = "GTiff",
assemblages<- raster('www/AssemblageMaxClass_Apr22_agg.tif')
#Assemblages = ratify(r)
#########

## Colour palette for assemblage raster
#assemcol <-c('#0000ee','#00ffff','#05aac1','#9a32cd','#00cd00','#9aff9a','#b40202','#ff0000','#ff8c00','#ffff00','#b4b404')# full colour
assemcol <-c("#9999F8","#99FFFF","#9BDDE6","#D6ADEB","#99EB99","#D6FFD6","#E19999","#FF9999","#FFD199","#FFFF99","#E1E19A")# muted colours


## Define colours for use in leaflet
pal <- colorFactor(
  palette = c('#0000ee','#00ffff','#05aac1','#eeaeee','#9a32cd','#00cd00','#9aff9a','#b40202','#ff0000','#ff8c00','#ffff00','#b4b404'),
  domain = data$cluster
)

pal_phy <- colorFactor(
  palette = c('#e31a1c','#FF62BC','#fdbf6f','#ff7f00','#FFFF32','#8681E5','#00BFC4','#A3A500','#1f78b4','#39B600'),
 # palette = c('#FF62BC','#A3A500','#e31a1c','#ff7f00','#8681E5','#fdbf6f','#00BFC4','#ffff32','#1f78b4','#39B600'),
  domain = data$phycluster
)

############################
## Agg region assemblage tif
library(terra)
library(leaflet)
assemblages2 <- rast('www/AssemblageMaxClass_Apr22_agg.tif')

uk_eez <-  st_read(pool, query ="SELECT * from spatial.UK_EEZ;")#
pal2 <- c("#9999F8","#99FFFF","#9BDDE6","#D6ADEB","#99EB99","#D6FFD6","#E19999","#FF9999","#FFD199","#FFFF99","#E1E19A")
r_uk_eez <- crop(assemblages2,uk_eez, mask=TRUE)

library(sf)
agg_region <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_regions;")
pal2 <- c("#9999F8","#99FFFF","#9BDDE6","#D6ADEB","#99EB99","#D6FFD6","#E19999","#FF9999","#FFD199","#FFFF99","#E1E19A")
r_agg_region <- crop(assemblages2, agg_region, mask=TRUE)

agg_siz <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_areas_siz where droped='FALSE';")# Read in data
pal2 <- c("#9999F8","#99FFFF","#9BDDE6","#D6ADEB","#99EB99","#D6FFD6","#E19999","#FF9999","#FFD199","#FFFF99","#E1E19A")
r_agg_siz <- crop(assemblages2, agg_siz, mask=TRUE)

############################

## Create map
output$map1 <-renderLeaflet({
leaflet() %>% 
    #addProviderTiles(providers$Esri.WorldImagery)%>%
    addProviderTiles(providers$Esri.WorldGrayCanvas,options = providerTileOptions(noWrap = TRUE))%>%
      addCircleMarkers(data=samclus,~as.numeric(samplelong), ~as.numeric(samplelat), radius = 4.5,stroke = T,weight=0.1, fillColor = ~pal_phy(phycluster),fillOpacity=1,group = "All (phy)",popup = paste0("<b>Programme: </b>", data$stationgroup,"<br>","<b>Array: </b>", data$stationsubgroup1,"<br>","<b>Station code: </b>", data$stationcode))%>%#
    addCircleMarkers(data=samclus,~as.numeric(samplelong), ~as.numeric(samplelat), radius = 2.5,stroke = T, weight=0.1,fillColor = ~pal(cluster),fillOpacity=1,group = "All (fauna)",popup = paste0("<b>Survey: </b>", samclus$survey,"<br>","<b>Sample Code: </b>", samclus$samplecode))%>% #
    addPolygons(data=euowf,color = "#444444", weight = 1, smoothFactor = 0.5,group = "euowf",popup = paste0("<b>Name: </b>", euowf$name))%>%
    addPolygons(data=owf,color = "#444444", weight = 1, smoothFactor = 0.5,group = "owf",popup = paste0("<b>Name: </b>", owf$Name_Prop, "<br>","<b>Status: </b>", owf$Inf_Status))%>%
    addPolygons(data=owf_cab,color = "#444444", weight = 1, smoothFactor = 0.5,group = "owf_cab",popup = paste0("<b>Name: </b>", owf_cab$Name_Prop, "<br>","<b>Status: </b>", owf_cab$Infra_Stat))%>%
    addPolygons(data=R4_chara,color = "#444444", weight = 1, smoothFactor = 0.5,group = "R4_chara",popup = paste0("<b>Name: </b>", R4_chara$Name))%>%
    addPolygons(data=R4_bid,color = "#444444", weight = 1, smoothFactor = 0.5,group = "R4_bid",popup = paste0("<b>Name: </b>", R4_bid$Name, "<br>","<b>Status: </b>", R4_bid$Bidding_Ar))%>%
    addPolygons(data=agg,color = "#444444", weight = 1, smoothFactor = 0.5,group = "agg (PIZ)",popup = paste0("<b>Name: </b>", agg$area_name, "<br>","<b>Number: </b>", agg$area_numbe))%>%
    addPolygons(data=siz,color = "orange", fill = FALSE,weight = 1.5, smoothFactor = 0.5,group = "agg (SIZ)",popup = paste0("<b>Name: </b>", siz$area_name, "<br>","<b>Number: </b>", siz$area_numbe))%>%
    addPolygons(data=ref,color = "#444444", weight = 1, smoothFactor = 0.5,group = "agg (REF)",popup = paste0("<b>Name: </b>", ref$box, "<br>","<b>Status: </b>", ref$sub_region))%>% 
    addPolygons(data=disp,color = "#444444", weight = 1, smoothFactor = 0.5,group = "disp",popup = paste0("<b>Name: </b>", disp$name_, "<br>","<b>Number: </b>", disp$site_))%>%
    addPolygons(data=wave,color = "#444444", weight = 1, smoothFactor = 0.5,group = "wave",popup = paste0("<b>Name: </b>", wave$Name_Prop, "<br>","<b>Status: </b>", wave$Inf_Status))%>%
    addPolygons(data=tidal,color = "#444444", weight = 1, smoothFactor = 0.5,group = "tidal",popup = paste0("<b>Name: </b>", tidal$Name_Prop, "<br>","<b>Status: </b>", tidal$Inf_Status))%>%
    addPolygons(data=tidal_cab,color = "#444444", weight = 1, smoothFactor = 0.5,group = "tidal_cab",popup = paste0("<b>Name: </b>", tidal_cab$Name_Prop, "<br>","<b>Status: </b>", tidal_cab$Infra_Stat))%>%
    addPolygons(data=mcz,color = "#444444", weight = 1, smoothFactor = 0.5,group = "mcz",popup = paste0("<b>Name: </b>", mcz$site_name))%>%
    addPolygons(data=sac,color = "#444444", weight = 1, smoothFactor = 0.5,group = "sac",popup = paste0("<b>Name: </b>", sac$site_name))%>%
    addPolygons(data=ncmpa,color = "#444444", weight = 1, smoothFactor = 0.5,group = "ncmpa",popup = paste0("<b>Name: </b>", ncmpa$site_name))%>%
    addPolygons(data=oga,color = "#444444", weight = 1, smoothFactor = 0.5,group = "oga",popup = paste0("<b>Number: </b>", oga$LICREF, "<br>","<b>Organisation: </b>", oga$LICORGGR))%>%
    addPolygons(data=agg_region,color = "#444444", weight = 1,fillOpacity = 0.01, smoothFactor = 0.5,group = "Assemblages (RSMP Region)")%>%#,popup = paste0("<b>Name: </b>", agg_region$stationsubgroup1)
    addRasterImage(assemblages,col=assemcol,opacity = 1,project = 3857,group = "Assemblages (All)")%>%
    addRasterImage(r_agg_region,col=pal2,opacity = 1,project = 3857,group = "Assemblages (RSMP Region)")%>%
     addRasterImage(r_agg_siz,col=pal2,opacity = 1,project = 3857,group = "Assemblages (Footprint)")%>%
    addRasterImage(r_uk_eez,col=pal2,opacity = 1,project = 3857,group = "Assemblages (EEZ)")%>%
    ######################
  addLayersControl(
    overlayGroups = c("All (fauna)","All (phy)","Assemblages","euowf","owf","owf_cab","R4_chara","R4_bid","agg (PIZ)","agg (SIZ)","agg (REF)","disp","wave","tidal","tidal_cab","oga","mcz","sac","ncmpa","Assemblages (All)","Assemblages (EEZ)","Assemblages (RSMP Region)","Assemblages (Footprint)"),options = layersControlOptions(collapsed = FALSE))%>%#"wave_cab",
    hideGroup(c("All (fauna)","All (phy)","Assemblages","euowf","owf","owf_cab","R4_chara","R4_bid","agg (PIZ)","agg (SIZ)","agg (REF)","disp","wave","tidal","tidal_cab","oga","mcz","sac","ncmpa","Assemblages (All)","Assemblages (EEZ)","Assemblages (RSMP Region)","Assemblages (Footprint)"))%>%
  
  ###############################
#   addLayersControl(
#    overlayGroups = c("Region","Footprint"),options = layersControlOptions(collapsed = FALSE))%>%#"wave_cab",
# hideGroup(c("Region","Footprint"))%>%#
  
  ################################
    setView(0.54,55.53,zoom=5.3)%>%
    addMouseCoordinates()
})

leafletOutput('map1') 
#__________________________________________________________________________________________
  #### UPDATE MAP WITH SELECTED SURVEYS ####
  #https://stackoverflow.com/questions/46979328/how-to-make-shiny-leaflet-map-reac-to-change-in-input-value-r
  
  # Watch for selection of new survey(s) 
  #observeEvent(input$regionInput, { 
    
#observeEvent(c(input$regionInput,  input$extractionareaInput),{
observeEvent(  input$siteInput,{
   site_id = input$siteInput
  
  if  ( site_id != ""    )  { 
  
    # Modify existing map
   leafletProxy("map1") %>%
      
      # Remove any previous selections 
      clearGroup("Selected (fauna)") %>%
      clearGroup("Selected (phy)") %>%
      clearGroup("selected") %>%
      
## Add selected PIZ/SIZ
         addPolygons(data=agg[agg$area_numbe == input$siteInput, ],fillColor = "#444444",stroke = T,opacity = 0.4, weight=1, color="#444444", fillOpacity = 0.2, smoothFactor = 0.5,group = "selected",popup = paste0("<b>Name: </b>", agg[agg$area_numbe == input$siteInput, ]$area_name, "<br>","<b>Number: </b>", agg[agg$area_numbe == input$siteInput, ]$area_numbe))%>%#, color="black"
         addPolygons(data=siz[siz$area_numbe == input$siteInput, ],color = "orange", fill = FALSE,weight = 1.5, smoothFactor = 0.5,group = "selected",popup = paste0("<b>Name: </b>", siz[siz$area_numbe == input$siteInput, ]$area_name, "<br>","<b>Number: </b>", siz[siz$area_numbe == input$siteInput, ]$area_numbe))%>%

        addCircleMarkers(data=data[data$stationsubgroup1 == input$regionInput, ],~as.numeric(samplelong), ~as.numeric(samplelat), radius = 4.5,stroke = T,weight=0.1, fillColor = ~pal_phy(phycluster),fillOpacity=1,group = "Selected (phy)",popup = paste0("<b>Programme: </b>", data$stationgroup,"<br>","<b>Array: </b>", data$stationsubgroup1,"<br>","<b>Station code: </b>", data$stationcode))%>%#
        addCircleMarkers(data=data[data$stationsubgroup1 == input$regionInput, ],~as.numeric(samplelong), ~as.numeric(samplelat), radius = 2.5,stroke = T, weight=0.1,fillColor = ~pal(cluster),fillOpacity=1,group = "Selected (fauna)",popup = paste0("<b>Programme: </b>", data[data$stationsubgroup1 == input$regionInput, ]$stationgroup,"<br>","<b>Array: </b>", data[data$stationsubgroup1 == input$regionInput, ]$stationsubgroup1,"<br>","<b>Station code: </b>", data[data$stationsubgroup1 == input$regionInput, ]$stationcode))%>% 
    addLayersControl(
    overlayGroups = c("Selected (fauna)","Selected (phy)","All (fauna)","All (phy)","euowf","owf","owf_cab","R4_chara","R4_bid","agg (PIZ)","agg (SIZ)","agg (REF)","disp","wave","tidal","tidal_cab","oga","mcz","sac","ncmpa","Assemblages (All)","Assemblages (EEZ)","Assemblages (RSMP Region)","Assemblages (Footprint)"),options = layersControlOptions(collapsed = FALSE))%>%#"wave_cab",
    hideGroup(c("Selected (phy)","All (fauna)","All (phy)","euowf","owf","owf_cab","R4_chara","R4_bid","agg (PIZ)","agg (SIZ)","agg (REF)","disp","wave","tidal","tidal_cab","oga","mcz","sac","ncmpa","Assemblages (All)","Assemblages (EEZ)","Assemblages (RSMP Region)","Assemblages (Footprint)"))#
#######################
#       addLayersControl(
#    overlayGroups = c("Region","Footprint"),options = layersControlOptions(collapsed = FALSE))%>%#"wave_cab",
# hideGroup(c("Region","Footprint"))#
    
    ####################
  }
  })

```


Column {.tabset .tabset-fade}
-----------------------------------------------------------------------
### Welcome  {data-padding=20}

<div>
<br>
<br>
<br>
<br>
<center>
<strong style="color: #044D94;font-size: 50px;">OneBenthic Baseline Tool (OBBT)<center>
```{r picturetest, echo = F, out.width = '12%'}

knitr::include_graphics("www/NEWLOGOCROPPED.png")#this works
```
<br>
<strong style="color: #5499C7;font-size: 30px;">Macrofaunal assemblages
<br>
<img src="www/OBBTWelcomeImage.png" width="300"></center>
<br>
```{r,out.width = "800px"}
## Header: Funders
knitr::include_graphics("www/logos2.png")#this works
```
</div>

### About  {data-padding=20}
<div>

```{r layersappfunders, echo = F, out.width = '100%'}

## Header: Modelling Methodology
h3("Purpose",style=c("color:#044D94"))
p("The OneBenthic Baseline Tool (OBBT) shows the faunal cluster identity of 0.1m2 grab and core samples (processed using a 1mm sieve) held in the",tags$a(href="https://sway.office.com/HM5VkWvBoZ86atYP?ref=Link", "OneBenthic"),"database.","Many of these samples are associated with existing monitoring stations, including those used by the marine aggregates industry under their Regional Seabed Monitoring Programme (RSMP). Cluster groups are based on methodology reported " ,tags$a(href="http://rdcu.be/wi6C", "here."),"New macrofaunal samples can be matched to existing cluster groups using the ",tags$a(href="https://rconnect.cefas.co.uk/onebenthic_faunalclusterid/", "OneBenthic Faunal Cluster ID Tool, "),"following methodology reported", tags$a(href="https://doi.org/10.1016/j.ocecoaman.2020.105361", "here."),"OBBT can be used in conjunction with the ",tags$a(href="https://openscience.cefas.co.uk/ob_mtest/", "OneBenthic M-test Tool"),"which assesses whether impacted sediments at ‘baseline’ stations remain suitable for recolonization by the original faunal assemblage type.")

h3("How to use the app",style=c("color:#044D94"))
p("Select a monitoring programme and survey array using the drop-down selection boxes. The map will then update with samples coloured according to faunal assemblage type (see 'Cluster Characteristics' tab). Various other map layers can be overlaid in the map (see 'Map Overlays' tab). A table in the 'Sampes' tab provides details of all samples collected at monitoring stations in the selected array. For RSMP arrays, the table includes details of the extraction areas (as defined by the potential secondary impact zone or SIZ) associated with each station, inclusing the licence holder's name.")

h3("Disclaimer",style=c("color:#044D94"))
p("Whilst due care and attention has been exercised in the collation of",tags$b("OneBenthic"),"data, Cefas assumes no responsibility for the quality or accuracy of the information. Users are advised to check data with the original source, and to critically assess whether data and data products are fit for the user's intended purpose.")

h3("Contact",style=c("color:#044D94"))
p("Get in touch to tell us how you've used the app, or to report technical issues (Email: keith.cooper@cefas.co.uk)")

```
</div>

### Faunal Cluster Characteristics  {data-padding=20}
<div>

```{r , echo = F, out.width = '90%'}

p("Biological characteristics of the macrofaunal assemblages identified through a k-means clustering of macrofaunal data (colonials included, forth-root transformation). Characterising species were identified through a SIMPER analysis and include taxa up to a total of 50% contribution. Letters in parenthesis identify the higher level taxonomic group: Amphipod crustacean (A), Ascidian tunicate (AT), Broyzoa (B), Bivalve Mollusc (BM), Crustacean (C), Decapod Crustacean (DC), Echinoderm (E), Polychaete (P), Phoronida (Ph), Nematoda (Ne). Values for Richness and Abundance are means and standard deviations. Arrows indicate the relative size of a value (High, Low and Medium).")

knitr::include_graphics("www/FaunalClusterChara.png")

```
</div>
### Map Overlays  {data-padding=20}
<div>

```{r rtable, echo = F, results='asis'}

## Header: Map overlays
h3("Map overlays",style=c("color:#044D94"))

## Table of overlay layers
map_overlays <- data.frame(
  Code=c(
    "Selected (fauna)",
    "Selected (phy)",
    "All (fauna)",
    "All (phy)",
    "euowf",
               "owf",
               "owf_cab",
               "R4_chara",
               "R4_bid",
               "agg (PIZ)",
         "agg (SIZ)",
         "agg (REF)",
               "disp",
               "wave",
               #"wave_cab",
               "tidal",
               "tidal_cab",
               "oga",
               "mcz",
               "sac",
               "ncmpa",
    'Assemblages (All)',
     'Assemblages (EEZ)',
     'Assemblages (RSMP Region)',
     'Assemblages (Footprint)'),
  Link=c(
    "NA",
    "NA",
    "NA",
     "NA",
     '<p><a href="https://www.emodnet-humanactivities.eu/search-results.php?dataname=Wind+Farms+%28Polygons%29"
      >Wind Farms (Polygons)</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::wind-site-agreements-england-wales-ni-the-crown-estate/explore?location=52.790200%2C-1.251504%2C7.42"
      >Offshore Wind Site Agreements (England, Wales & NI), The Crown Estate</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::wind-cable-agreements-england-wales-ni-the-crown-estate/explore?location=52.698964%2C-1.244512%2C7.39"
      >Offshore Wind Cable Agreements (England, Wales & NI), The Crown Estate</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::offshore-wind-leasing-round-4-characterisation-areas-england-wales-and-ni-the-crown-estate/explore?location=52.677790%2C-1.394816%2C7.24"
     >Offshore Wind Leasing Round 4 Characterisation Areas (England, Wales and NI), The Crown Estate</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::offshore-wind-leasing-round-4-bidding-areas-england-wales-and-ni-the-crown-estate/explore?location=53.040550%2C-0.830858%2C7.17"
      >Offshore Wind Leasing Round 4 Bidding Areas (England, Wales and NI), The Crown Estate</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::aggregates-site-agreements-england-wales-ni-the-crown-estate/explore?location=52.033181%2C-1.121135%2C7.89"
      >Offshore Minerals Aggregates Site Agreements (England, Wales & NI), The Crown Estate</a></p>',
    
     "NA",
    
     "NA",
    
         '<p><a href="http://data.cefas.co.uk/#/View/407"
      >UK Disposal Site Layer, Cefas</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::wave-site-agreements-england-wales-ni-the-crown-estate/explore?location=50.777918%2C-5.092345%2C9.32"
     >Offshore Wave Site Agreements (England, Wales & NI), The Crown Estate</a></p>',
    
         #'<p><a href="https://opendata.arcgis.com/datasets/bf376b05c6ae489b8b8687d6b7d6525d_0.geojson">Visit W3Schools.com!</a></p>',
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::tidal-stream-site-agreements-england-wales-ni-the-crown-estate/explore?location=52.888850%2C-3.683844%2C7.48"
      >Offshore Tidal Stream Site Agreements (England, Wales & NI), The Crown Estate</a></p>',
    
         '<p><a href="https://opendata-thecrownestate.opendata.arcgis.com/datasets/thecrownestate::tidal-stream-cable-agreements-england-wales-ni-the-crown-estate/explore?location=51.877184%2C-5.315998%2C17.11"
      >Offshore Tidal Stream Cable Agreements (England, Wales & NI), The Crown Estate</a></p>',
    
         '<p><a href="https://data-ogauthority.opendata.arcgis.com/datasets/oga-licences-wgs84-3/explore?location=56.616000%2C-5.050750%2C5.16"
      >OGA Licences WGS84, Oil and Gas Authority</a></p>',
    
        '<p><a href="https://hub.jncc.gov.uk/assets/ade43f34-54d6-4084-b66a-64f0b4a5ef27"
          >Marine Conservation Zones (MCZ)</a></p>',
    
         '<p><a href="https://hub.jncc.gov.uk/assets/ade43f34-54d6-4084-b66a-64f0b4a5ef27"
      >Special Area of Conservation (SAC)</a></p>',
    
         '<p><a href="https://hub.jncc.gov.uk/assets/ade43f34-54d6-4084-b66a-64f0b4a5ef27"
      >Nature Conservation Marine Protected Areas (Scotland)</a></p>',
     'NA',
     'NA',
     'NA',
     'NA'),
  
  Description=c("Faunal cluster group for selected stations (see Cooper and Barry (2017) for details).",
    "Physical cluster group for selected stations (see Cooper and Barry (2017) for details).",
    "Faunal cluster group for all UK macrofaunal samples in OneBenthic (see Cooper and Barry (2017) for details).",
                "Physical cluster group for all UK macrofaunal samples in OneBenthic (see Cooper and Barry (2017) for details).",
    "Offshore wind installations in European seas from the European Marine Observation and Data Network (EMODnet)",
          "This dataset represents all current offshore wind farm agreements in pre-planning, planning, construction and operational phases, as well as Preferred Projects subject to HRA, in English, Welsh and Northern Irish waters.",
          "This dataset represents all current export cables for offshore wind farm agreements in pre-planning, planning, construction and operational phases in English, Welsh and Northern Irish waters.",
          "This dataset represents areas of seabed defined by The Crown Estate within each of the Bidding Areas which are considered to present the greatest opportunity to Bidders based on thorough assessment of the constraints.",
          "This dataset represents the external boundary of the areas of seabed within which Bidders can propose projects through the Round 4 leasing process.",
          "This dataset represents all current marine aggregates licence agreements (Primary Impact Zones) in English, Welsh and Northern Irish waters.",
          "Potential secondary impact zones (SIZ) associated with marine aggregage extraction licenses",
          "Reference sites fo rthe Regional Seabed Monitoring Programme",
          "UK Disposal Sites (layer maintained by Cefas)",
          "This dataset represents all current wave agreements in English, Welsh and Northern Irish waters.",
          #"This dataset represents all current wave agreements in English, Welsh and Northern Irish waters.",
          "This dataset represents all current tidal stream agreements in English, Welsh and Northern Irish waters",
          "This dataset represents all current export cables for tidal stream agreements in English, Welsh and Northern Irish waters.",
          "OGA Licences WGS84, Oil and Gas Authority",
          "Marine Conservation Zones (MCZ)",
          "Special Area of Conservation (SAC)",
          "Nature Conservation Marine Protected Areas (Scotland)",
     'full extent of benthic assemblage model',
     'area of UK EEZ covered by the assemblage model',
     'polygon covering all licences',
     'area of seabed covered by all regional primary and secondary impact zones (PIZs/SIZs)'))


## Create a table for map overlays
library(knitr)
  library(kableExtra)

    kable(map_overlays, escape=FALSE,format = "html") %>%
      column_spec (1, bold = T)%>%
      kable_styling(bootstrap_options = c("striped","hover", "condensed"))#%>%
      #scroll_box( height = "900px")#width = "900px",

```
</div>


### Samples  {data-padding=20}

<div>
```{r, warning=FALSE,message=FALSE}
library(sf)

#### IDENTIFY POLYGON  FOR POINTS ####
#sf::sf_use_s2(FALSE)# fix: https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data
sink <- capture.output(sf::sf_use_s2(FALSE))# use this instead to stop message appearing (see https://github.com/r-spatial/sf/issues/1782)

## Check class of points and polygon objects
#class(agg) #"sf"         "data.frame"
#class(data)# "data.frame"


## Create a reactive object for selected data
react <- reactive({
    #saminsiz <- subset(data, stationsubgroup1 == input$regionInput)
   saminsiz <-  data[ which(data$stationsubgroup1==input$regionInput), ]
      st_points <- saminsiz %>%
  mutate_at(vars(samplelong, samplelat), as.numeric) %>%   # coordinates must be numeric
  st_as_sf(
    coords = c("samplelong", "samplelat"),
    agr = "constant",
    crs = 4326,        # nad83 / new york long island projection
    stringsAsFactors = FALSE,
    remove = F)

## Check CRS
#st_crs(st_points)

## Get licence area for each sample (where relevant)
stations_in_siz <- st_join(st_points, siz, join =st_within)
   st_geometry(stations_in_siz) <- NULL #remove geom colum otherwise it appears in DT
   #stations_in_siz2 <- stations_in_siz[,c(7,1,2,4,5,3,6,16,19)]
   #colnames(stations_in_siz2) <- c("Station","Sample","Year","Longitude","Latitude","Gear","Cluster","Licence","Company")
   stations_in_siz2 <- stations_in_siz[,c(8,1,2,4,5,3,6,7,17,20)]
   colnames(stations_in_siz2) <- c("Station","Sample","Year","Longitude","Latitude","Gear","Cluster (fauna)","Cluster (phy)","Licence","Company")
   return(stations_in_siz2)
  })

## Create table
DT::renderDataTable(
    
    #DT::datatable(react(), options = list(pageLength = 10, scrollX='400px',scrollY=FALSE,columnDefs = list(list(className = 'dt-center', targets = c(0:10)))),escape=FALSE)#"all"
    DT::datatable(react(), fillContainer = TRUE,options = list(pageLength = 10, scrollY = "475px",columnDefs = list(list(className = 'dt-center', targets = c(0:10)))),escape=FALSE)#"all"
  )

```

</div>

<div>
```{r}
# Create placeholder for the downloadButton
uiOutput("downloadUI")
```
</div>

<div>
```{r, warning=FALSE,message=FALSE}


# Create the actual downloadButton
output$downloadUI <- renderUI( {
  downloadButton("downBtn", "Download data", style = "width:50%;")
})

# Add download handling
output$downBtn <- downloadHandler(
  filename = function() {
    "data.csv"
  },
  content = function(file) {
    write.csv(react(), file, row.names = FALSE)
  }
)

```
</div>

### Areas involved  {data-padding=20}

<div>
```{r, warning=FALSE,message=FALSE}
## Load polygon
library (RPostgres)
library(pool)
library(sf)
library(dplyr)
Sys.setenv(R_CONFIG_ACTIVE = "one_benthic")
dw <- config::get()
pool <- dbPool(drv = dbDriver(dw$driver),
               dbname = dw$database,
               host = dw$server,
               port =  dw$port,
               user = dw$uid,
               password = dw$pwd)
#agg_region <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_regions;")
#v <- vect(system.file("ex/lux.shp", package="terra"))
#plot(agg_region)
#ag_region <- agg_region[which(agg_region$stationsubgroup1 == 'Anglian RSMP'),]
#plot(agg_region)
# subset area using polygons
#r_agg_region <- crop(r, agg_region, mask=TRUE)
## Load raster and vector layers
library(terra)
#r <- rast("C:/Users/kmc00/OneDrive - CEFAS/R_PROJECTS/OneBenthicBaselineToolNew/R/www/Assemblages.tif")#
r <- rast("www/AssemblageMaxClass_Apr22_agg.tif")
#r <- rast('www/AssemblageMaxClass_Apr22.tif')
#r <- round(r/100)
names(r) <- 'Assemblages'
###############

## RASTER EXTENT
raster_extent <-  st_read(pool, query ="SELECT * from spatial.raster_extent_polygon;")# Read in data
#plot(raster_extent) # plot polygons
#names(raster_extent)# Check col names
raster_extent2 <- raster_extent[,c(1,2,3,4)] # take cols of interest
#names(raster_extent2)# Check col names
names(raster_extent2)[2] <- 'name'
names(raster_extent2)[3] <- 'area_km2'# Update col names so all polygon dfs have same names and can be joined
raster_extent3 <- st_cast(raster_extent2, "POLYGON")# convert from multipolygon to polygon
#names(raster_extent3)
#class(raster_extent3)
#head(raster_extent3)
raster_extent3$name <- 'All'

## UK EEZ
uk_eez <-  st_read(pool, query ="SELECT * from spatial.UK_EEZ;")# Read in data
#plot(uk_eez) # plot polygons
#names(uk_eez)# Check col names
uk_eez2 <- uk_eez[,c(1,2,5,6)] # take cols of interest
#names(uk_eez2)# Check col names
names(uk_eez2)[3] <- 'area_km2'# Update col names so all polygon dfs have same names and can be joined
uk_eez3 <- st_cast(uk_eez2, "POLYGON")# convert from multipolygon to polygon
#names(uk_eez3)
##class(uk_eez3)
uk_eez3$name <- 'EEZ'

## AGGREGATE REGIONS
agg_region <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_regions;")# Read in data
#plot(agg_region) # plot polygons
#names(agg_region)# Check col names
names(agg_region)[2] <- 'name'## Update col names so all polygon dfs have same names and can be joined
#names(agg_region)
#class(agg_region)
#View(agg_region)

## AGGREGATE SIZs
agg_siz <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_areas_siz where droped='FALSE';")# Read in data
#plot(agg_siz) # plot polygons
#names(agg_siz)# Check col names
agg_siz2 <- agg_siz[,c(1,6,10,19)] # take cols of interest
#head(agg_siz2)


names(agg_siz2) <- c('id','name','area_km2','geom')## Update col names so all polygon dfs have same names and can be joined
agg_siz3 <- st_cast(agg_siz2, "POLYGON")# convert from multipolygon to polygon
#names(agg_siz3)
#class(agg_siz3)
#head(agg_siz3)

## AGGREGATE SIZs ALL
agg_siz_all <-  st_read(pool, query ="SELECT * from ap_marine_aggregate.extraction_areas_siz where droped='FALSE';")# Read in data
#plot(agg_siz_all) # plot polygons
#names(agg_siz_all)# Check col names
agg_siz_all2 <- agg_siz_all[,c(1,4,6,10,19)] # take cols of interest
#head(agg_siz_all2)

names(agg_siz_all2) <- c('id','region','name','area_km2','geom')## Update col names so all polygon dfs have same names and can be joined
agg_siz_all3 <- st_cast(agg_siz_all2, "POLYGON")# convert from multipolygon to polygon
#names(agg_siz_all3)
#class(agg_siz_all3)
#head(agg_siz_all3)

## SIZ HUM
agg_siz_hum <- agg_siz_all3%>%filter(region=='Humber RSMP') # subset polygons for region
agg_siz_hum2 <- agg_siz_hum[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_hum2)[2] <- 'name'# update col names
#class(agg_siz_hum2)
agg_siz_hum_comb <- agg_siz_hum2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_hum_comb)
agg_siz_hum_comb$name <- 'Humber Footprint'# add in missing cols
agg_siz_hum_comb$id <- 'Humber Footprint'# add in missing cols
agg_siz_hum_comb$area_km2 <- ''# add in missing cols
agg_siz_hum_comb2 <- agg_siz_hum_comb[,c(4,3,5,1)] # get cols in correct order
#agg_siz_hum_comb2 # check order
#agg_siz_hum_comb2$name <- 'H Footprint'

## SIZ A
agg_siz_ang <- agg_siz_all3%>%filter(region=='Anglian RSMP') # subset polygons for region
agg_siz_ang2 <- agg_siz_ang[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_ang2)[2] <- 'name'# update col names
#class(agg_siz_ang2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_ang_comb <- agg_siz_ang2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_ang_comb)
agg_siz_ang_comb$name <- 'Anglian Footprint'# add in missing cols
agg_siz_ang_comb$id <- 'Anglian Footprint'# add in missing cols
agg_siz_ang_comb$area_km2 <- ''# add in missing cols
agg_siz_ang_comb2 <- agg_siz_ang_comb[,c(4,3,5,1)] # get cols in correct order
#agg_siz_ang_comb2 # check order
#agg_siz_ang_comb2$name <- 'A Footprint'

## SIZ T
agg_siz_t <- agg_siz_all3%>%filter(region=='Thames RSMP') # subset polygons for region
agg_siz_t2 <- agg_siz_t[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_t2)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_t_comb <- agg_siz_t2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_t_comb$name <- 'Thames Footprint'# add in missing cols
agg_siz_t_comb$id <- 'Thames Footprint'# add in missing cols
agg_siz_t_comb$area_km2 <- ''# add in missing cols
agg_siz_t_comb2 <- agg_siz_t_comb[,c(4,3,5,1)] # get cols in correct order
#agg_siz_sc_comb2 # check order
#agg_siz_sc_comb2$name <- 'SC Footprint'

## SIZ SC
agg_siz_sc <- agg_siz_all3%>%filter(region=='South Coast RSMP') # subset polygons for region
agg_siz_sc2 <- agg_siz_sc[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_sc2)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_sc_comb <- agg_siz_sc2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_sc_comb$name <- 'South Coast Footprint'# add in missing cols
agg_siz_sc_comb$id <- 'South Coast Footprint'# add in missing cols
agg_siz_sc_comb$area_km2 <- ''# add in missing cols
agg_siz_sc_comb2 <- agg_siz_sc_comb[,c(4,3,5,1)] # get cols in correct order
#agg_siz_sc_comb2 # check order
#agg_siz_sc_comb2$name <- 'SC Footprint'

## SIZ EC
agg_siz_ec <- agg_siz_all3%>%filter(region=='East Channel RSMP') # subset polygons for region
agg_siz_ec2 <- agg_siz_ec[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_ec2)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_ec_comb <- agg_siz_ec2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_ec_comb$name <- 'East Channel Footprint'# add in missing cols
agg_siz_ec_comb$id <- 'East Channel Footprint'# add in missing cols
agg_siz_ec_comb$area_km2 <- ''# add in missing cols
agg_siz_ec_comb2 <- agg_siz_ec_comb[,c(4,3,5,1)] # get cols in correct order
#agg_siz_sc_comb2 # check order
#agg_siz_sc_comb2$name <- 'SC Footprint'

## SIZ NW457
agg_siz_nw457 <- agg_siz_all3%>%filter(region=='North West (457)') # subset polygons for region
agg_siz_nw4572 <- agg_siz_nw457[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_nw4572)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_nw457_comb <- agg_siz_nw4572 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_nw457_comb$name <- 'North West (457) Footprint'# add in missing cols
agg_siz_nw457_comb$id <- 'North West (457) Footprint'# add in missing cols
agg_siz_nw457_comb$area_km2 <- ''# add in missing cols
agg_siz_nw457_comb2 <- agg_siz_nw457_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ BC531
agg_siz_bc531 <- agg_siz_all3%>%filter(region=='Bristol Channel (531)') # subset polygons for region
agg_siz_bc5312 <- agg_siz_bc531[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_bc5312)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_bc531_comb <- agg_siz_bc5312 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_bc531_comb$name <- 'Bristol Channel (531) Footprint'# add in missing cols
agg_siz_bc531_comb$id <- 'Bristol Channel (531) Footprint'# add in missing cols
agg_siz_bc531_comb$area_km2 <- ''# add in missing cols
agg_siz_bc531_comb2 <- agg_siz_bc531_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ BC476
agg_siz_bc476 <- agg_siz_all3%>%filter(region=='Bristol Channel (476)') # subset polygons for region
agg_siz_bc4762 <- agg_siz_bc476[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_bc4762)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_bc476_comb <- agg_siz_bc4762 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_bc476_comb$name <- 'Bristol Channel (476) Footprint'# add in missing cols
agg_siz_bc476_comb$id <- 'Bristol Channel (476) Footprint'# add in missing cols
agg_siz_bc476_comb$area_km2 <- ''# add in missing cols
agg_siz_bc476_comb2 <- agg_siz_bc476_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ BC526
agg_siz_bc526 <- agg_siz_all3%>%filter(region=='Bristol Channel (526)') # subset polygons for region
agg_siz_bc5262 <- agg_siz_bc526[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_bc5262)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_bc526_comb <- agg_siz_bc5262 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_bc526_comb$name <- 'Bristol Channel (526) Footprint'# add in missing cols
agg_siz_bc526_comb$id <- 'Bristol Channel (526) Footprint'# add in missing cols
agg_siz_bc526_comb$area_km2 <- ''# add in missing cols
agg_siz_bc526_comb2 <- agg_siz_bc526_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ GWS
agg_siz_gws <- agg_siz_all3%>%filter(region=='Goodwin Sands RSMP') # subset polygons for region
agg_siz_gws2 <- agg_siz_gws[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_gws2)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_gws_comb <- agg_siz_gws2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_gws_comb$name <- 'Goodwin Sands Footprint'# add in missing cols
agg_siz_gws_comb$id <- 'Goodwin Sands Footprint'# add in missing cols
agg_siz_gws_comb$area_km2 <- ''# add in missing cols
agg_siz_gws_comb2 <- agg_siz_gws_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ HS
agg_siz_hs <- agg_siz_all3%>%filter(region=='Hilbre Swash (Area 392_393)') # subset polygons for region
agg_siz_hs2 <- agg_siz_hs[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_hs2)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_hs_comb <- agg_siz_hs2 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_hs_comb$name <- 'Hilbre Swash (Area 392, 393) Footprint'# add in missing cols
agg_siz_hs_comb$id <- 'Hilbre Swash (Area 392, 393) Footprint'# add in missing cols
agg_siz_hs_comb$area_km2 <- ''# add in missing cols
agg_siz_hs_comb2 <- agg_siz_hs_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ BC472
agg_siz_bc472 <- agg_siz_all3%>%filter(region=='Bristol Channel (472)') # subset polygons for region
agg_siz_bc4722 <- agg_siz_bc472[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_bc4722)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_bc472_comb <- agg_siz_bc4722 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_bc472_comb$name <- 'Bristol Channel (472) Footprint'# add in missing cols
agg_siz_bc472_comb$id <- 'Bristol Channel (472) Footprint'# add in missing cols
agg_siz_bc472_comb$area_km2 <- ''# add in missing cols
agg_siz_bc472_comb2 <- agg_siz_bc472_comb[,c(4,3,5,1)] # get cols in correct order

## SIZ BC455 459 Bedwyn
agg_siz_bc455 <- agg_siz_all3%>%filter(region=='Bristol Channel (455, 459, Bedwyn)') # subset polygons for region
agg_siz_bc4552 <- agg_siz_bc455[,c(1,2,4,5)] # cols of interest: id, region, area_km2, geom
colnames(agg_siz_bc4552)[2] <- 'name'# update col names
#class(agg_siz_sc2)
sf_use_s2(FALSE)#TURN SPHERICAL GEOMETRY OFF TO PREVENT ERROR
agg_siz_bc455_comb <- agg_siz_bc4552 %>%  summarise() %>%  mutate(region = st_area(.))# union all polygons (not an obvious geometry merge tool, but quite effective)
#plot(agg_siz_sc_comb)
agg_siz_bc455_comb$name <- 'Bristol Channel (455, 459, Bedwyn) Footprint'# add in missing cols
agg_siz_bc455_comb$id <- 'Bristol Channel (455, 459, Bedwyn) Footprint'# add in missing cols
agg_siz_bc455_comb$area_km2 <- ''# add in missing cols
agg_siz_bc455_comb2 <- agg_siz_bc455_comb[,c(4,3,5,1)] # get cols in correct order
#######
#######

## Stitch all polygons together
all_poly <- rbind(raster_extent3,uk_eez3,agg_region,agg_siz3,agg_siz_hum_comb2,agg_siz_sc_comb2,agg_siz_ang_comb2, agg_siz_t_comb2,agg_siz_ec_comb2,agg_siz_nw457_comb2,agg_siz_bc531_comb2,agg_siz_bc476_comb2,agg_siz_bc526_comb2,
                  agg_siz_gws_comb2,agg_siz_hs_comb2,agg_siz_bc472_comb2,agg_siz_bc455_comb2 )
#head(all_poly)
#plot(all_poly)
#all_poly <- poly

## Create a df with ID and polyname 
all_poly_names <- as.data.frame(all_poly[,2])# Extract polygon names
all_poly_names2 <- all_poly_names %>% mutate(ID = row_number())# turn row numers into a col called 'ID'
#head(all_poly_names2)

## AREAS AND PROPORTIONS FOR ALL REGIONAL POLYGONS ##
library(terra)

# extract cluster by polygon
example<-terra::extract(r,all_poly, ID=T)

## Number of cells by cluster by poly
example2 <- example%>%group_by(ID)%>%count(Assemblages)
#head(example2)
example2 <- as.data.frame(example2)

## Remove rows with NA
example3 <- example2[complete.cases(example2), ]
#head(example3)

## Add in polygon names
merge_test <- merge(example3,all_poly_names2, by='ID')
#View(merge_test)
## Proxt search terms


## Now do a tes extraction
#selected_data <- merge_test[which(merge_test$name=='NW Europe'|merge_test$name=='UK EEZ'|merge_test$name=='South Coast RSMP'|merge_test$name=='127'|merge_test$name=='SC Footprint'),]#|merge_test$name=='Humber RSMP'|merge_test$name=='506'

#selected_data <- merge_test[which(merge_test$name=='NW Europe'|merge_test$name=='UK EEZ'|merge_test$name=='Humber RSMP'|merge_test$name=='514/1'|merge_test$name=='H Footprint'),]#|merge_test$name=='Humber RSMP'|merge_test$name=='506'

#selected_data <- merge_test[which(merge_test$name=='NW Europe'|merge_test$name=='UK EEZ'|merge_test$name=='Anglian RSMP'|merge_test$name=='240'|merge_test$name=='A Footprint'),]#|merge_test$name=='Humber RSMP'|merge_test$name=='506'

##########################

footprint <- reactive({
  if (input$regionInput == 'Humber RSMP') {
  return("Humber Footprint")
} else if (input$regionInput == 'Anglian RSMP') {
  return("Anglian Footprint")
} else if (input$regionInput == 'Thames RSMP') {
  return("Thames Footprint")
} else if (input$regionInput == 'South Coast RSMP') {
  return("South Coast Footprint")
} else if (input$regionInput == 'East Channel RSMP') {
  return("East Channel Footprint")
} else if (input$regionInput == 'Bristol Channel (531)') {
  return("Bristol Channel (531) Footprint")
} else if (input$regionInput == 'Bristol Channel (476)') {
  return("Bristol Channel (476) Footprint")
}else if (input$regionInput == 'Bristol Channel (526)') {
  return("Bristol Channel (526) Footprint")
}else if (input$regionInput == 'Goodwin Sands RSMP') {
  return("Goodwin Sands Footprint")
}else if (input$regionInput == 'Hilbre Swash (Area 392_393)') {
  return("Hilbre Swash (Area 392, 393) Footprint")
}else if (input$regionInput == 'North West (457)') {
  return("North West (457) Footprint")
}else if (input$regionInput == 'Bristol Channel (472)') {
  return("Bristol Channel (472) Footprint")
}else if (input$regionInput == 'Bristol Channel (455, 459, Bedwyn)') {
  return("Bristol Channel (455, 459, Bedwyn) Footprint")
}
})
########################


selected_data3 <- reactive({
selected_data <- merge_test[which(merge_test$name=='All'|
                                    merge_test$name=='EEZ'|
                                    merge_test$name==input$regionInput|
                                    merge_test$name==footprint()|
                                    merge_test$name==input$siteInput),]#|merge_test$name==input$regionInput|merge_test$name==input$siteInput|merge_test$name=='A Footprint'
#head(selected_data)
selected_data2 <- selected_data%>%group_by(ID)%>%mutate(sum=sum(n),perc=n/(sum(n))*100)
##################

selected_data2$Assemblages[selected_data2$Assemblages == 1] <- 'A1'
selected_data2$Assemblages[selected_data2$Assemblages == 2] <- 'A2a'
selected_data2$Assemblages[selected_data2$Assemblages == 3] <- 'A2b'
selected_data2$Assemblages[selected_data2$Assemblages == 4] <- 'B1a'
selected_data2$Assemblages[selected_data2$Assemblages == 5] <- 'C1a'
selected_data2$Assemblages[selected_data2$Assemblages == 6] <- 'C1b'
selected_data2$Assemblages[selected_data2$Assemblages == 7] <- 'D1'
selected_data2$Assemblages[selected_data2$Assemblages == 8] <- 'D2a'
selected_data2$Assemblages[selected_data2$Assemblages == 9] <- 'D2b'
selected_data2$Assemblages[selected_data2$Assemblages == 10] <- 'D2c'
selected_data2$Assemblages[selected_data2$Assemblages == 11] <- 'D2d'

#################
return(selected_data2)
})

#renderPlot({
#par(mar=c(1,1,1,1))
#  par(mfrow=c(1,1))
#library(scales)
#library(plotly)
#p <- ggplot(data=selected_data3(), aes(x=factor(Assemblages), y=n, fill=factor(Assemblages))) +
#  geom_bar(position="stack", stat="identity") +#,stat="identity"
  #geom_col(position = "fill") +#,stat="identity"
  #geom_label( x=3.5, aes(y=labelPosition, label=label), size=6) +
  #scale_fill_brewer(palette=4) +
 # scale_fill_manual(values = c('#0000ee','#00ffff','#05aac1','#9a32cd','#00cd00','#9aff9a','#b40202','#ff0000','#ff8c00','#ffff00','#b4b404'))+
  #coord_polar(theta="y") +
  #xlim(c(2, 4)) +
  #theme_void() +
  #facet_wrap(~factor(name,levels=c('NW Europe','UK EEZ','South Coast RSMP','SC Footprint','127')),scales="free")+
  #facet_wrap(~factor(name,levels=c('NW Europe','UK EEZ','Humber RSMP','H Footprint','514/1')),scales="free")+
  #facet_wrap(~factor(name,levels=c('NW Europe','UK EEZ','Anglian RSMP','A Footprint','240')),scales="free")+
 # facet_wrap(~factor(name),scales="free")+
 # theme(legend.position = "none")+
 # scale_y_continuous(labels = label_comma())

#p
#ggplotly(p)
#})

```

<div style= "height:620px; width: 750px">
```{r, fig.width = 12, fig.height=20}
level_order2 <- reactive({
level_order <- c('All',
                 'EEZ',
                 unique(agg_region$name),
                 'Anglian Footprint',
                 'Humber Footprint',
                 'Thames Footprint',
                 'South Coast Footprint',
                 'East Channel Footprint',
                 'Bristol Channel (531) Footprint',
                 'Bristol Channel (476) Footprint',
                 'Goodwin Sands Footprint',
                 'Hilbre Swash (Area 392, 393) Footprint',
                 'North West (457) Footprint',
                 'Bristol Channel (526) Footprint',
                 'Bristol Channel (472) Footprint',
                 'Bristol Channel (455, 459, Bedwyn) Footprint',
                 unique(agg_siz$area_numbe))
return(level_order)
})

p('The plots below show the area of seabed covered by different benthic faunal assemblages at a variety of spatial scales including:')
#br()
p('i) ',tags$b('All'), ' - full extent of benthic assemblage model,') 
p('ii) ',tags$b('EEZ'),' - area of UK EEZ covered by the assemblage model,') 
p('iii) ',tags$b('RSMP Region'),' - polygon covering all licences,') 
p('iv) ',tags$b('Footprint'),' - area of seabed covered by all regional primary and secondary impact zones (PIZs/SIZs), and')
p('v) ',tags$b('Dredging Site'), '- footprint of potential dredging effect (PIZ and SIZ) for selected site.')
#br() 
p("Charts should be viewed together with the relevant associated map layers: Assemblages (All), Assemblages (EEZ), Assemblages (RSMP Region) and Assemblages (Footprint). These layers can be toggled on/off in the map window. Note the faunal identity of individual samples (map layers: 'selected (fauna)' and 'All (fauna)') may sometimes differ to that of the underlying model. This is expected and consistent with the notion that all models are imperfect.")

renderPlotly({
#par(mar=c(1,1,1,1))
  par(mfrow=c(1,1))
library(scales)
library(plotly)
p <- ggplot(data=selected_data3(), aes(x=factor(Assemblages), y=n, fill=factor(Assemblages))) +
  geom_bar(position="stack", stat="identity") +#,stat="identity"
  #geom_col(position = "fill") +#,stat="identity"
  #geom_label( x=3.5, aes(y=labelPosition, label=label), size=6) +
  #scale_fill_brewer(palette=4) +
  #Scale_fill_manual(values = c('#0000ee','#00ffff','#05aac1','#9a32cd','#00cd00','#9aff9a','#b40202','#ff0000','#ff8c00','#ffff00','#b4b404'))+
  scale_fill_manual(values = c("#9999F8","#99FFFF","#9BDDE6","#D6ADEB","#99EB99","#D6FFD6","#E19999","#FF9999","#FFD199","#FFFF99","#E1E19A"))+# muted colours
  #coord_polar(theta="y") +
  #xlim(c(2, 4)) +
  #theme_void() +
  #facet_wrap(~factor(name,levels=c('NW Europe','UK EEZ','South Coast RSMP','SC Footprint','127')),scales="free")+
  #facet_wrap(~factor(name,levels=c('NW Europe','UK EEZ','Humber RSMP','H Footprint','514/1')),scales="free")+
  #facet_wrap(~factor(name,levels=c('NW Europe','UK EEZ','Humber RSMP','Anglian RSMP','North West (457)','Bristol Channel (531)','H Footprint','A Footprint','240','514/1','127','1804/1','1805')),scales="free")+
 facet_wrap(~factor(name,levels=level_order2()),scales="free")+
  theme(legend.position = "none",
        plot.margin = margin(0, 0, 0,0, "cm"),
        axis.title=element_text(size=10))+#,face="bold"
  theme(text=element_text(size=10))+
  xlab("Assemblage")+
  ylab("Area")+
  scale_y_continuous(labels = label_comma())+
  theme(axis.text.x = element_text(angle = 90))#, vjust = 0.5, hjust=1


ggplotly(p)
})


```
</div>


